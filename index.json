[{"categories":null,"content":"As probably with anyone experimenting with Innodb Cluster and MySQL 8, I’ve spent a good deal of time with MySQL Shell. I think for some old-timers MySQL Shell can initially come across as odd or difficult to understand. Partially, I think it is because Shell offers a deluge of new features from: managing local sandbox mysql instances 3 different shell languages (SQL, Javascript, and Python), full management APIs for Innodb Cluster, parallel logical backup and restore utilities and probably a whole lot more I haven’t found yet. However, as I’ve grown more comfortable with it, I can say that I do like it’s possibilities. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:0:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"Credential storage One of Shell’s features is credential storage. By default, you will be prompted if you want to save the password you use to make a successful mysql connection. This is fine as a convenience, but what is more interesting to me is the fact that the credential store is pluggable. But how? The interface for creating a credential storage plugin is not documented (as far as I can tell) in the manual. The best (and only) documentation I could find on this is from a MySQL dev blog from 2018, see the lower section ‘Custom credential helpers’. In a nutshell, a credential helper is just an executable that Shell runs on the same system you are running MySQL shell on. The executable must implement 5 subcommands in the format mysql-secret-store-yourname \u003csubcommand\u003e. Some subcommands take JSON on standard input, some emit JSON on standard output, some do both. The executable should exit with a 0 on success or a 1 on failure for any of the comands. The executable must be in a specific directory so that Shell can find it. Simple enough, right? The 5 subcommands are: store - stores credentials passed in get - gets requested credentials erase - drop specific credentials from the store list - list all available credentials version - output a version number ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:1:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"RDS and Aurora How might I use the credential store? Well, I am using RDS and Aurora more and more these days. As a DBA type at my company, I need to access a wide variety of databases on AWS. All of these have been setup to allow access to me as a DBA using a standard IAM user using temporary IAM credentials. The basic pre requisites are: I have credentials to access a given AWS account with a specific (and limited) role that allows me to generate IAM tokens There is a mysql user setup connected to the role with a special plugin that associates it with IAM Authentication. To get DB access I then: I use my AWS credentials to generate an IAM token I setup an SSH tunnel to a place where I can access the network addresses of the DB I run my mysql client more or less as normal, but I have to pass the IAM token as my password and use the SSH tunnel port for proper routing Using the AWS CLI and pseudo-bash, it would basically look like this: ssh -L \"$LOCAL_PORT:$ENDPOINT:$PORT\" $SSH_BASTION \u0026 TOKEN=`aws rds generate-db-auth-token \\ --hostname \"$ENDPOINT\" \\ --port \"$PORT\"\\ --profile \"$AWS_PROFILE\" \\ --username \"$MYSQL_USER/IAM ROLE NAME\"` mysql -u \"$MYSQL_USER/IAM ROLE NAME\" \"-p=$TOKEN\" -h 127.0.0.1 -p $LOCAL_PORT The token is good for 15 minutes, so I can cache the value for up to that long and subsequent connections can re-use it. I can also re-use the SSH tunnel as long as it is open and connecting to the endpoint I want to use. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:2:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"Meeting the two in the middle What if there was a way to connect these two systems? I don’t have a huge use case for storing static credentials, but what if I could write a Credential store that would handle fetching these temporary credentials for me? It turns out that this is pretty easy. I can use any scripting or compiled language I want, provided I implement the needed interface and deal with Server URLs. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:3:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"Turning Server URLs into what we need One big obstacle however is that the interface provides a single key: Server URL. This is comprised of: user name host name port number Somehow I have to take that input and generate the following information so I can get my IAM token: the AWS config profile name for the target DB’s account. Other AWS credential types could be used here instead. the AWS region of the specific host I’m connecting to the RDS/Aurora endpoint I’m connecting to (probably the hostname in the URL) the IAM role to get a token for (I believe this has to be the mysql user name, but I could be mistaken here) (probably the user name in the URL) The solution for how to do this depends greatly on conventions very specific to my environment. I ended up using a combination of parsing (i.e., to extract the region) and convention (my aws profile names and my RDS endpoints share common elements I can parse out). How you might need to implement this is going to be specific to your setup as well, but it could be as simple as a local YAML / JSON config file you manage by hand. For example: my-endpoint.us-east-1.rds.amazonaws.com: aws_profile: profile_name region: us-east-1 Then you can take that profile and region and use it in your AWS API/CLI calls. YMMV. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:4:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"The interface But how should the interface behave? This isn’t necessarily what the good folks at Oracle expected when they designed credential helpers. Let’s talk about how we might handle each subcommand: ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:5:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"get This is the meat and potatoes where we need to turn the requested ServerURL into an IAM token. We convert the given Server URL into our needed AWS information and use either the AWS API or CLI to generate a token. This method also handles caching the token for the 15 minutes. If get is called again, we can use the cached version and skip all the AWS calls. If the cache is expired, we fetch a new token as before. This is a DB secret, so storage of this cache should be handled with some care. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:5:1","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"store No-op. We don’t actually store credentials with this helper, just retrieve. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:5:2","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"erase Shell calls this for some reason the authentication fails. I implemented this to drop the Server URL in my cache in case the token needed to be regenerated, e.g., the token expired but my cache TTL didn’t work. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:5:3","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"list I simply list the Server URLs in my cache, i.e., my cache keys. My cache doesn’t actually drop entries until get is called, so this serves as a list of servers I’ve successfully authenticated to in the past (remember failed auth calls erase on a key). I don’t know if I will keep it that way or not yet. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:5:4","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"version Just emit some version string for my handler ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:5:5","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"Handling the tunnel It turns out that MySQL Shell already has support for ssh tunneling. One less thing to worry about! When I connect in the shell, I just give it the ssh bastion hostname I use above, and it does the rest. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:6:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"Tying it together To use my credential helper, I have to have the executable be named mysql-secret-store-\u003cmyname\u003e and it must be located in the same folder as the MySQL Shell binary. I ended up writing my helper in Golang and when I have a new version I like to run go install, so I simply created a symlink from my go bin directory to where Homebrew installed Shell for me: ln -sf $GOPATH/bin/mysql-secret-store-rds /usr/local/mysql-shell/bin/mysql-secret-store-rds I have to then update my shell’s config to use this helper MySQL JS \u003e \\option --persist credentialStore.helper='rds' You may or may not want this to be a permanent setting. I am planning on making mine permanent, but extending my handler to be a transparent wrapper around another handler when I determine the Server URL is not RDS/Aurora. Finally, I’m ready to make a connection: MySQL JS \u003e shell.connect({ ssh:\"bastion.host.name\", host:\"rds.endpoint.rds.amazonaws.com\", port: \"3306\", user: \"dba-user\", \"ssl-ca\":\"/Users/jayj/.aws/rds-combined-ca-bundle.pem\", \"ssl-mode\": \"VERIFY_CA\" }) Creating a session to 'dba-user@rds.endpoint.rds.amazonaws.com:3306?ssl-ca=%2FUsers%2Fjayj%2F.aws%2Frds-combined-ca-bundle.pem\u0026ssl-mode=VERIFY_CA' Opening SSH tunnel to bastion.host.name:22... Fetching schema names for auto-completion... Press ^C to stop. Closing old connection... Your MySQL connection id is 3692 Server version: 5.7.12-log MySQL Community Server (GPL) No default schema selected; type \\use \u003cschema\u003e to set one. \u003cClassicSession:dba-user@rds.endpoint.rds.amazonaws.com:3306\u003e MySQL bastion.host.name \u003e rds.endpoint.rds.amazonaws.com:3306 ssl JS \u003e \\sql select @@aurora_version; +------------------+ | @@aurora_version | +------------------+ | 2.11.0 | +------------------+ 1 row in set (0.0445 sec) Success! Like I said before, I can’t really open source my version of this because of the environment specific stuff I do to get from a Server URL to the AWS metadata I need to lookup the token. I will say that my resulting Go code is only about ~300 lines and most of that is some semi-ugly string parsing. My hope with this post is it inpires you to consider other ways MySQL Shell’s pluggable credential helper might be useful for you. ","date":"2023-01-18","objectID":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/:7:0","tags":["rds","aurora","mysql shell"],"title":"RDS/Aurora IAM DB access with MySQL Shell","uri":"/posts/2023/01/rds/aurora-iam-db-access-with-mysql-shell/"},{"categories":null,"content":"As part of an overwhelming stampede to migrate to the cloud, we are looking at using AWS RDS Aurora MySQL as a platform for some of our database clusters. Lots of people have lots of opinions about Aurora, some of them are probably justified and some probably not. I was interested in testing the high availability and disaster recovery capabilities of Aurora. To be specific, I am testing Aurora v2 (though I expect v3 to work the same). I am also specifically testing Aurora Global databases ","date":"2022-12-02","objectID":"/posts/2022/12/aurora-global-failovers/:0:0","tags":["aurora","failover","disaster recovery"],"title":"Aurora Global Failovers","uri":"/posts/2022/12/aurora-global-failovers/"},{"categories":null,"content":"Aurora Global Clusters Aurora global databases are relatively simple to understand. Perhaps the best way is to describe it in the order in which you would construct it: Create your first regional cluster Create a global cluster from the first cluster Create replica clusters in other regions Using Aurora global databases, User Guide for Aurora, AWS Documentation Only one cluster can take writes at a time, and it is designated as the Primary cluster. The other cluster(s) are considered Secondary. Replication across region is done by the Storage layer and does not use standard MySQL replication. ","date":"2022-12-02","objectID":"/posts/2022/12/aurora-global-failovers/:1:0","tags":["aurora","failover","disaster recovery"],"title":"Aurora Global Failovers","uri":"/posts/2022/12/aurora-global-failovers/"},{"categories":null,"content":"Aurora Endpoints Another important concept to understand is Aurora endpoints. Each cluster (in each region) has two default endpoints, a writer and a reader. The writer points to the currently primary writer instance and the reader points to all the reader instance(s) as you might expect. These endpoints are how your client would connect to the Aurora cluster and they automatically follow when instance roles changes, for example if Writer instance failed over to another in-region. Each instance in the cluster also have their own direct endpoints, but use of these is not recommended since instance roles can change automatically. In global clusters, endpoints still exist for each regional cluster. There is no concept of a global endpoint. Whichever cluster is the Primary has it’s Writer endpoint active. Secondary cluster’s have inactive Writer endpoints. To be specific, the endpoint on a secondary cluster has the Inactive status and the name cannot be resolved in DNS. The writer endpoint is inactive in this secondary cluster Ergo, the application must be aware of the endpoints in it’s deployment region. If the application is active in the non-primary Aurora region, it must somehow be aware of the endpoint in the Primary region or else not allow writes to the Aurora cluster. To be fair, there is an Aurora feature for Global Database Write forwarding that I have not experimented much with yet. ","date":"2022-12-02","objectID":"/posts/2022/12/aurora-global-failovers/:2:0","tags":["aurora","failover","disaster recovery"],"title":"Aurora Global Failovers","uri":"/posts/2022/12/aurora-global-failovers/"},{"categories":null,"content":"Planned Failover (aka Switchover) Now that we have our shiny global cluster, let’s test failover! AWS calls this planned failover, though hopefully there isn’t much failure involved. Our goal is to safely change which cluster is primary without any dataloss and (hopefully) not a lot of application downtime. This action can be taken from the AWS console with the ‘Fail over global database’ action on the Global database object, or else via the AWS rds CLI. Anyone who has done mysql primary switchovers ever should be familiar with the basic steps here: Set the old primary read-only Wait for replication to catch up Set the new primary read-write Aurora is no exception, but there are a few additional steps. Because the new primary cluster’s writer endpoint is Inactive, it must be made active. To test this, I connect a sysbench client to my primary cluster’s endpoint. Because there is no global endpoint, I have to pay attention to when the secondary cluster’s endpoint becomes available in DNS so I can reconnect my client to it instead. However, I have discovered that Here is a representative sample of the timings of my operations: Time Action / Event 00:00 Failover started 02:19 Writes cease in primary 02:38 Reads case on primary endpoint 05:05 Writes start on new primary cluster’s instance endpoint 14:19 The writer endpoint resolves in DNS From these timings, we can see clearly that the global failover operation is really supposed to finish around the 5 minute mark (after approximately 3 minutes of write downtime). Around this time, I can see the AWS console indicating that the new primary cluster’s writer endpoint indicates it is in the Available state, yet it does not resolve in DNS. I have tested this many times, and to be fair it is not always this slow. I have observed the writer endpoint resolving in DNS much sooner than it did in my example here. I believe this is an AWS bug and AWS claims they will be fixing it soon. Bug In my testing (as of December 2022) write downtime can currently take up to 15 minutes. Warning Even when the above DNS propogation bug is fixed (assuming that’s what it is), I expect that the best that can be expected for writer downtime will be approximately 3-5 minutes. Tip Anyone who needs to run routine DR testing on Aurora Global clusters will want to strongly consider doing so off-peak hours ","date":"2022-12-02","objectID":"/posts/2022/12/aurora-global-failovers/:3:0","tags":["aurora","failover","disaster recovery"],"title":"Aurora Global Failovers","uri":"/posts/2022/12/aurora-global-failovers/"},{"categories":null,"content":"Unplanned Failover Amazon’s unplanned failover documentation is pretty interesting in the sense that they explicitly tell you not to use the failover button that you use for Planned failovers. Instead the steps can be summarized as such: Stop writing to your primary db (assuming their primary region is available enough that you can reach your application). Pick your target cluster to failover to Remove the target cluster from the global database Start writing to the new target cluster. Step 3 effectively splits the target cluster such that you now have two database clusters. Depending on the severity of the AWS region outage, you may or may not be able to do any of the following: See if your primary cluster is up at all and taking writes Take some kind of action to ensure said primary cluster is not taking writes any more Execute any kind of reasonable STONITH/fencing procedures. Based on the fact that AWS recommends against using it, it also that the “Failover” action for global databases is not trustworthy enough to even attempt to execute in the event of a primary region failure and so you have to take an alternative process in the event of a true failure. Personally, I’d prefer if something at least tried to execute the proper failover steps in case the outage is intermittent enough to occasionally be able to reach the region/cluster experiencing the problem. As far as the observed time to execute an Unplanned failover, detaching the secondary cluster is a relatively fast operation. In that situation, nothing is setting the primary cluster read-only nor waiting for replication lag to catch up (at least in the sense that it can confirm all writes from the old primary have made it to the new). However, the same DNS propogation issue exists in this scenario that will delay the availability of the writer endpoint. Therefore, once this process is executed, I estimate it takes around 2-14 minutes or 2-4 minutes once the bug is fixed. ","date":"2022-12-02","objectID":"/posts/2022/12/aurora-global-failovers/:4:0","tags":["aurora","failover","disaster recovery"],"title":"Aurora Global Failovers","uri":"/posts/2022/12/aurora-global-failovers/"},{"categories":null,"content":"What AWS states about Failover In short, the manual seems to acknowledge that “minutes” is to be expected: Quote For an Aurora global database, RTO can be in the order of minutes. source While related marketing content seems to paint a rosier picture: Quote If your primary Region suffers a performance degradation or outage, you can promote one of the secondary Regions to take read/write responsibilities. An Aurora cluster can recover in less than 1 minute even in the event of a complete Regional outage. This provides your application with an effective Recovery Point Objective (RPO) of 1 second and a Recovery Time Objective (RTO) of less than 1 minute, providing a strong foundation for a global business continuity plan. source If you find any other public statements, I’d be happy to hear about them! ","date":"2022-12-02","objectID":"/posts/2022/12/aurora-global-failovers/:5:0","tags":["aurora","failover","disaster recovery"],"title":"Aurora Global Failovers","uri":"/posts/2022/12/aurora-global-failovers/"},{"categories":null,"content":"After a long haiatus, I am back in the world of MySQL and infrastructure. I spent over 10 years at Percona, first as a MySQL Consultant, then as a manager, then as an IT doer of things, finally as the Director of IT. Earlier this year I made the decision to return to an individual contributor role at a new (to me) company, Block, or more specifically, Square. ","date":"2022-11-01","objectID":"/posts/2022/11/back-in-the-saddle/:0:0","tags":null,"title":"Back in the Saddle","uri":"/posts/2022/11/back-in-the-saddle/"},{"categories":null,"content":"What I’m doing now No doubt some old-timers will remember my blogs at Percona, mostly about PXC and Galera. I’m still interested in cluster tech, but now I’m working with MySQL Innodb Cluster. This is pretty similar to Galera architecturally. It’s a (mostly) synchronous, shared-nothing, Innodb-based cluster. An extra fun dimension here is deploying this at a large scale on AWS. Because I’ve been removed from the MySQL ecosystem for so long (despite working at Percona), it’s been fun to catch up on all that’s new from MySQL community, including: MySQL 8.0 (I last used 5.6 seriously) MySQL shell and the AdminAPI MySQL router Innodb Cluster itself On the infrastructure side, I’ve been delving deeper into: AWS Autoscaling groups Terraform Golang I’m hoping to restart my technical blogging as I am learning more about all these topics and to even make it back to a conference or two in the future. ","date":"2022-11-01","objectID":"/posts/2022/11/back-in-the-saddle/:1:0","tags":null,"title":"Back in the Saddle","uri":"/posts/2022/11/back-in-the-saddle/"}]